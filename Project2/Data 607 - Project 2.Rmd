---
title: "DATA 607 - Project 2"
author: "Adam Douglas"
date: "Due 10/7/2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
```

## Introduction
The concept of tidy data was popularized by Hadley Wickham in his paper titled "Tidy Data"[^1]. By putting data into a tidy format, one could perform data analysis within R much quicker and easier, because the format works very well with R's vectorized functions.

This project will highlight these concepts by taking 3 examples of "untidy" data and, using tools that Wickham himself created, transform them into a tidy format. Then, we can see how much easier analysis can be done thanks to tidy data.

## Set-Up
First, we will load the packages we require to do our tidying work. The two tools we will use most for this task are `tidyr` and `dplyr`. These are both included, along with some other useful tools for visualization and analysis, in a larger package known as `tidyverse`.

```{r load tidyverse, message=FALSE, warning=FALSE}
library(tidyverse)
```

## Example 1
Our first example comes from the United Nations (UN) Department of Economic and Social Affairs[^2]. The UN tracks, amongst many other things, migration of peoples from one area of the globe to another. The data, freely available on the UN website, was highlighted by my classmate Juanelle Marks.

We will be looking specifically at the data titled "By destination and origin" which shows migration to and from various countries across several years.

### Raw Data
The raw data exists as an Excel file. The only transformation made to the original file was to remove extra tabs that we're not loading (for a smaller file size) and to filter out subtotal rows by color.

Since this exists as Excel, we will use the `readxl` package from the Tidyverse to assist in the loading of the data.

```{r lib readxl}
library(readxl)
```

Unfortunately, readxl does not yet work with URLs, so we load the data from a local file. Using the `read_excel` function, this is quite easy to do.

```{r load UN data}
# Load the proper sheet and only the cell range we want
UN <- read_excel("UN_MigrantStockByOriginAndDestination_2017.xlsx",
           sheet="Table 1",
           range="A16:IG1906")

# Display the data
UN
```

Looking at the raw data, we first see some missing column names, which we can fix easily:

```{r fix UN columns}
# Using the Excel document, fix the first 6 column names
UN <- UN %>% rename(year = X__1, 
              sort = X__2, 
              destination = X__3, 
              notes = X__4, 
              code = X__5, 
              typeOfData = X__6)
```

### Tidying
The next piece we tackle is the fact that we have observations (source countries) saved as individual variables. We can use the `gather` function from `tidyr` to fix this:

```{r gather UN}
# This creates a new column called "source" from the column headers
#   and puts the values into a "people" column, effectively gathering
#   the data into a longer (rather than wider) format

tidyUN <- UN %>% gather(key = "source", value="people", 7:241)

# Select a subset to see how the data looks now
tidyUN %>% filter(destination == "France", year == 2017)
```

Finally, we notice that the people column is stored as a character vector, not as numeric which would be more appropriate for this sort of variable. Before we can fix that, we have to get rid of the `..` used in the Excel sheet for missing data and replace it with an NA.

```{r fix people column}
# Replace the ..'s with NA
tidyUN$people[tidyUN$people == ".."] <- NA

# Change the column type
tidyUN$people <- as.integer(tidyUN$people)
```

Our data should now be in a tidy format and ready for analysis.

### Analysis
There are many different types of analyses we could perform on this data, and that only increases if we were to include other data from the UN site. For this demonstration, we'll keep to some simple examples.

First, let's take a random country like France and see where the top 10 migrant populations come from:

```{r UN largest source}
france <- tidyUN %>% filter(year == 2017, destination == "France",
                  source!= "Total") %>%
  group_by(as.character(year), source) %>%
  summarize(n = sum(people, na.rm=TRUE)) %>%
  top_n(10,n) %>%
  arrange(desc(n))

kable(france, col.names = c("Year","Country","# People"), 
      caption="Migrant Population in France by Country of Origin (Top 10)",
      format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```

We can also look at which country holds the largest migrant population:

```{r most migrants}
top5Dest <- tidyUN %>% filter(year == 2017, source == "Total") %>%
  group_by(as.character(year), destination) %>%
  summarize(n = sum(people, na.rm=TRUE)) %>%
  top_n(10,n) %>%
  arrange(desc(n))

kable(top5Dest, col.names = c("Year","Country","# People"), 
      caption="Migrant Population by Country (Top 10)",
      format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```

We can also track over time

```{r US Migrants}
US <- tidyUN %>% filter(destination == "United States of America",
                  source== "Total") %>%
  group_by(as.character(year)) %>%
  rename(Year = `as.character(year)`) %>%
  summarize(millionPeople = sum(people, na.rm=TRUE)/1000000)

US %>% ggplot(aes(x=Year, y=millionPeople)) +
  geom_col(fill="deepskyblue3") + ylab("People (Millions)") +
  ggtitle("United States Migrant Population")
```

***

## Example 2
The next example is taken from the Department of Education's National Student Loan Data System (NSLDS)[^3]. The specific file is a portfolio summary showing outstanding interest and balances by acedemic year and loan type.

### Raw Data
The raw data is in a table inside an Excel document. So, we will use the `readxl` package like before.

```{r read loans}
loan <- read_excel("PortfolioSummary.xls")

loan
```

Looking at the data, we have our work cut out for us. First we'll do some basic cleanup:

```{r cleanup loans}
# The first 3 lines are sheet headers and unnecessary
loan <- loan[-(1:3),]

# Fix our variable names
names(loan) <- c("year","period","Direct Loan Dollars Outstanding",
                 "Direct Loan Recipients","FFEL Dollars Outstanding",
                 "FFEL Loan Recipients","Perkins Loan Dollars Outstanding",
                 "Perkins Loan Recipients","Total Dollars Outstanding",
                 "Total Recipients")

# The next 2 lines are column headers and redundant
loan <- loan[-(1:2),]

# If we look at the end of the data, there are more unnecessary rows
#   left over from the Excel file.
loan <- head(loan,-5)

loan
```

Now our data frame looks more complete now.

### Tidying

We have a few issues outstanding with the data before we can call it tidy. First, we are missing some data in the `year` and `period` columns.

```{r cleanup loans continued}
# Fill in years
loan <- fill(loan,year)

# Missing periods are for the whole year
loan[(is.na(loan$period)),2] <- "YR"

loan
```

Finally, we see that observations (type of loan) is put into columns as if they were variables. We can easily fix this with `gather` from the `dplyr` package.

```{r gather loan}
# Because we have multiple variables in columns, we need to be
#   more careful in our use of "gather"

# Move all into a single column
tidyLoan <- gather(loan, key="type", value="amount", -year, -period)

# Get the word "loan" out so we normalize the names
tidyLoan$type <- str_replace(tidyLoan$type,"\\s{1}(Loan)","")

# Now split the "type" column, because it really contains two variable types
tidyLoan <- 
  tidyLoan %>%
  extract(type, c("loanType", "measure"),"([[:alpha:]]+)\\s{1}(.+)")

# Then spread those into their respective columns
tidyLoan <- tidyLoan %>% spread(measure, amount)

# Finally, fix column names and column types
tidyLoan <- rename(tidyLoan, dollars = `Dollars Outstanding`, recipients = Recipients)

tidyLoan$dollars <- as.numeric(tidyLoan$dollars)

tidyLoan$recipients <- as.numeric(tidyLoan$recipients)

tidyLoan
```

We now have our data in a tidy format with 116 observations (the original 29 times 4 - 3 loan types and 1 total) and can begin analyzing.

### Analysis

Alone, this data does not afford too much in the way of analysis, however we can look at a few items of interest.

First, over time, the total loan amounts:

```{r amounts over time}
# Filter to a single value per year
tidyLoan %>% 
  filter(loanType == "Total", period == "YR" | period == "Q4") %>%
  ggplot(aes(x=year, y=dollars)) +
    geom_col(fill= "darkgreen") +
    geom_line(aes(x=year, y=dollars, group=1), col="red") +
    ggtitle("Total Student Loan Balance") +
    xlab("Year") + ylab("Dollars (Billions)") +
    ylim(0,1500)
```

The graph shows that there has been a **significant** increase in student loan balances over the 10 years represented. In fact, within the first 6 years it doubled.

Is this because more students are going to college?

```{r students over time}
tidyLoan %>% 
  filter(loanType == "Total", period == "YR" | period == "Q4") %>%
  ggplot() +
    geom_col(aes(x=year, y=recipients),fill= "steelblue3") +
    geom_line(aes(x=year, y=recipients, group=1), col="red") +
    ggtitle("Total Student Loan Recipients") +
    xlab("Year") + ylab("Recipients (Millions)")
```

Looking at these graphs, it appears that there is more outstanding balance over time than can be explained by simply having more students. One may conclude that there is another variable at work here, perhaps cost of education is rising? Further analysis would be required to confirm or deny that.

***

## Example 3
This final example comes from the NYS Data website [^4] and is a list of Supplemental Nutrition Assistance Program (SNAP) caseloads and expenditures. This program, previously referred to as "food stamps" is an important safety net low-income families and children.

### Raw Data
Because we have the data in a CSV format, we can pull it directly from GitHub:

```{r get SNAP data, message=FALSE}
SNAP <- read_csv(url("https://raw.githubusercontent.com/lysanthus/Data607/master/Project2/SNAP.csv"),col_names = TRUE)

SNAP
```

Looking at our raw CSV data, we can see that the data is broken out into years and months and divided by county. Furthermore, there are 3 types of observations stored as variable types: "Temporary-Assistance", "Non-Temporary Assistance" and "Total". We also have 3 actual variables: "Households", "Persons", "Benefits".

### Tidying

Because we have a relatively "clean" dataset, we can proceed with reshaping it into a tidy format. We will use a similar methodology that we used in example 2 above.

```{r tidy SNAP}
# Move all into a single column
tidySNAP <- gather(SNAP, key="type", value="amount", 6:14)

# Get the word "SNAP" out so we normalize the names
tidySNAP$type <- str_replace(tidySNAP$type,"\\s{1}(SNAP)","")

# Get the word "Assistance" out so we normalize the names
tidySNAP$type <- str_replace(tidySNAP$type,"\\s{1}(Assistance)","")

# Now split the "type" column, because it really contains two variable types
tidySNAP <- 
  tidySNAP %>%
  extract(type, c("benefitType", "measure"),"([-[:alpha:]]+)\\s{1}(.+)")

# Then spread those into their respective columns
tidySNAP <- tidySNAP %>% spread(measure, amount)

tidySNAP
```

Now we have a proper tidy data set to analyze.

### Analysis

First, let's look at how many dollars are being spent per year:

```{r SNAP per year}
tidySNAP %>% 
    filter(benefitType == "Total") %>%
    group_by(Year) %>% summarize(spend = sum(Benefits, rm.na=TRUE)/1000000000,
                                 people = sum(Persons, rm.na=TRUE), 
                                 perPerson = spend/people) %>%
    ggplot() +
    geom_col(aes(x=Year, y=spend),fill= "darkgreen") +
    ggtitle("Total NYS SNAP Spending (statewide)") +
    xlab("Year") + ylab("Dollars (billions)")
```

This gives us some idea of the total amounts being spent, though there is no evidence that these numbers are adjusted for inflation in any way.

We could also compare the dollars per resident of each county to get a per-capita spending value (with the assistance of a census dataset).

```{r, message=FALSE}
# Get the census data
census <- read_csv(url(
  "https://raw.githubusercontent.com/lysanthus/Data607/master/Project2/census.csv"),
  col_names = TRUE)

# We're going to limit to 2017 only
census <- census %>% filter(Year == 2017, Geography != "New York State")

# Remove the word "County" for easy joining
census$Geography <- str_replace(census$Geography,"\\sCounty","")

# Same thing with the SNAP data
SNAP2017 <- tidySNAP %>% 
        filter(benefitType == "Total", Year == "2017") %>%
        group_by(Year, District) %>% summarize(spend = sum(Benefits, rm.na=TRUE),
                                 people = mean(Persons, rm.na=TRUE))

# Join the datasets and get some measures
SNAPbyCounty <-
  left_join(SNAP2017,census, by=c("District"="Geography")) %>%
  select(year = Year.x, county= District, spend, people, population = Population) %>%
  mutate(spendPC = round(spend / population,2), recipPC = (people / population))

top10SNAP <- SNAPbyCounty %>% top_n(10,spendPC) %>% arrange(desc(spendPC)) %>%
  select(year, county, spendPC)

kable(top10SNAP, col.names = c("Year","County","Spend per Capita"), 
      caption="Top 10 Total SNAP Spending by County (2017)") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "left")
```



[^1]: http://vita.had.co.nz/papers/tidy-data.pdf
[^2]: http://www.un.org/en/development/desa/population/migration/data/estimates2/estimates17.shtml
[^3]: https://catalog.data.gov/dataset/national-student-loan-data-system/resource/02a63933-37ef-4b14-a45a-90dd7b523b29
[^4]: https://data.ny.gov/Human-Services/Supplemental-Nutrition-Assistance-Program-SNAP-Cas/dq6j-8u8z
